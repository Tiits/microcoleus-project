{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Cyanobacteria Toxicity Classification Notebook",
   "id": "7178d22ef7a6dad8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Setup & Configuration",
   "id": "9071dafcb911554"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import os\n",
    "from datetime import date\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "from torchvision import models, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from src.config_utils import load_config\n",
    "from PIL import Image\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "config = load_config(path='../configs/config_finetune_resnet18.yaml')\n",
    "\n",
    "FIG_OUT  = os.path.join('..','outputs','figures', 'all', 'finetune_resnet18')\n",
    "\n",
    "# Génération du Run ID: date + git hash\n",
    "today = date.today().isoformat()\n",
    "commit = subprocess.check_output([\"git\",\"rev-parse\",\"--short\",\"HEAD\"]).decode().strip()\n",
    "run_id = f\"{today}_{commit}\"\n",
    "\n",
    "print(\"Run ID :\", run_id)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Data Preparation",
   "id": "521fe26231326b8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define transforms based on config\n",
    "data_cfg = config['augmentation']\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(tuple(data_cfg['resize'])),\n",
    "    transforms.RandomHorizontalFlip() if data_cfg['horizontal_flip'] else transforms.Lambda(lambda x: x),\n",
    "    transforms.RandomRotation(data_cfg['rotation']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_cfg['normalization']['mean'], std=data_cfg['normalization']['std'])\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = datasets.ImageFolder(root=os.path.join( '../', config['data']['path']), transform=train_transform)\n",
    "\n",
    "# Split into train/val\n",
    "total = len(dataset)\n",
    "train_size = int(config['data']['train_split'] * total)\n",
    "val_size = total - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=config['data']['batch_size'], shuffle=True, num_workers=config['data']['num_workers'])\n",
    "val_loader   = DataLoader(val_set,   batch_size=config['data']['batch_size'], shuffle=False, num_workers=config['data']['num_workers'])"
   ],
   "id": "844dc7800c0a0261",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Model Definition",
   "id": "79730fe664d90f58"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_cfg = config['model']\n",
    "model = getattr(models, model_cfg['name'])(weights=ResNet18_Weights.DEFAULT)\n",
    "if hasattr(model, 'fc'):\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, model_cfg['num_classes'])\n",
    "elif hasattr(model, 'classifier'):\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, model_cfg['num_classes'])\n",
    "model = model.to(config['training']['device'])\n"
   ],
   "id": "853fdceb9f31919a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Training Loop",
   "id": "a0cbad38762724f1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=float(config['training']['learning_rate']), weight_decay=float(config['training']['weight_decay']))\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(loader, desc='Train'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct.double() / total\n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "\n",
    "def eval_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc='Val'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct.double() / total\n",
    "    return epoch_loss, epoch_acc.item(), np.array(all_labels), np.array(all_preds)"
   ],
   "id": "bd2a3187b8bf9d91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training and validation\n",
    "history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "for epoch in range(config['training']['epochs']):\n",
    "    print(f\"Epoch {epoch+1}/{config['training']['epochs']}\")\n",
    "    t_loss, t_acc = train_one_epoch(model, train_loader, criterion, optimizer, config['training']['device'])\n",
    "    v_loss, v_acc, y_true, y_pred = eval_model(model, val_loader, criterion, config['training']['device'])\n",
    "    history['train_loss'].append(t_loss)\n",
    "    history['val_loss'].append(v_loss)\n",
    "    history['train_acc'].append(t_acc)\n",
    "    history['val_acc'].append(v_acc)\n",
    "    print(f\"Train loss: {t_loss:.4f}, acc: {t_acc:.4f} | Val loss: {v_loss:.4f}, acc: {v_acc:.4f}\\n\")"
   ],
   "id": "9f910a6f831662f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "hist_path = '../outputs/checkpoints/all/finetune_resnet18/history_finetune_resnet18.pkl'\n",
    "pd.to_pickle(history, hist_path)"
   ],
   "id": "e1dcdedc7acbaba7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Results Visualization",
   "id": "202bbced8f293ee0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot loss and accuracy curves\n",
    "epochs = range(1, config['training']['epochs']+1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, history['train_acc'], label='Train Acc')\n",
    "plt.plot(epochs, history['val_acc'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Sauvegarde de la figure des coubres accuracy\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_accuracy_curves.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Courbes sauvegardées dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "1f7a8bd52b4f8793",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
    "plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Sauvegarde de la figure des coubres loss\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_loss_curves.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Courbes sauvegardées dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "f1c2a450655addcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confusion matrix\n",
    "target_names = dataset.classes\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Sauvegarde de la figure de confusion matrix\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_confusion_matrix.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Matrice sauvegardée dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "8528752a16559fcd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Classification report\n",
    "# print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "report_df = pd.DataFrame(classification_report(y_true, y_pred, target_names=target_names, output_dict=True)).T\n",
    "\n",
    "csv_path = os.path.join(FIG_OUT, f\"{run_id}_classification_report.csv\")\n",
    "report_df.to_csv(csv_path, index=True)\n",
    "print(\"Report CSV sauvegardé dans :\", csv_path)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, len(report_df) * 0.5 + 1))\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=report_df.round(2).values,\n",
    "    rowLabels=report_df.index,\n",
    "    colLabels=report_df.columns,\n",
    "    loc='center'\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "img_path = os.path.join(FIG_OUT, f\"{run_id}_classification_report.png\")\n",
    "fig.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(\"Report image sauvegardé dans :\", img_path)"
   ],
   "id": "a2f97a535f7350d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Save Model & Config",
   "id": "df403037d07c8dea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.makedirs('../outputs/checkpoints/all/finetune_resnet18', exist_ok=True)\n",
    "torch.save(model.state_dict(), f'../outputs/checkpoints/all/finetune_resnet18/{run_id}_model.pth')\n",
    "\n",
    "with open(f'../outputs/configs/all/{run_id}_config_finetune_resnet18.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print('Training complete. Model and config saved in outputs')"
   ],
   "id": "89edf61ea16372d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Grad-CAM Interpretability",
   "id": "f6b5ac1da05d35be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "n_display = 10\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = math.ceil(n_display / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols,\n",
    "                         figsize=(n_cols * 4, n_rows * 4),\n",
    "                         dpi=300)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(n_display):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    tensor_aug, true_label = val_set[idx]\n",
    "    orig_path, _ = val_set.dataset.samples[val_set.indices[idx]]\n",
    "    orig_img: Image.Image = Image.open(orig_path).convert('RGB')\n",
    "    W, H = orig_img.size\n",
    "\n",
    "    orig_resized = transforms.Resize(tuple(data_cfg['resize']))(orig_img)\n",
    "    input_tensor = vis_transform(orig_resized).unsqueeze(0)\n",
    "\n",
    "    outputs = model(input_tensor)\n",
    "    pred_label = outputs.argmax(dim=1).item()\n",
    "\n",
    "    grayscale_cam = cam_extractor(input_tensor=input_tensor)[0]\n",
    "\n",
    "    cam_img = Image.fromarray((grayscale_cam * 255).astype(np.uint8))\n",
    "    cam_img = cam_img.resize((W, H), resample=Image.BILINEAR)\n",
    "    cam_resized = np.array(cam_img, dtype=np.float32) / 255.0\n",
    "\n",
    "    rgb_orig = np.array(orig_img, dtype=np.float32) / 255.0\n",
    "    cam_on_orig = show_cam_on_image(rgb_orig, cam_resized, use_rgb=True)\n",
    "\n",
    "    ax.imshow(cam_on_orig)\n",
    "    ax.set_title(f\"True: {dataset.classes[true_label]}\\nPred: {dataset.classes[pred_label]}\",\n",
    "                 fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "for ax in axes[n_display:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_grad-cam.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Image sauvegardée dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "6ecb3dcc0eb38cc3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
