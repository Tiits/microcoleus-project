{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Entrainement finetune de modèles pré-entraînés\n",
    "Ce notebook présente :\n",
    "- Pipeline de prétraitement à partir des splits de finetune\n",
    "- Définition d’un modèle pré-entraîné\n",
    "- Entraînement et évaluation\n",
    "- Sauvegarde du meilleur modèle"
   ],
   "id": "2d07658de0762063"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Setup & Configuration",
   "id": "b5054dc7049f42ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from datetime import date\n",
    "import subprocess\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision.models import ResNet18_Weights\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import models, datasets\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from src.config_utils import load_config\n",
    "from PIL import Image\n",
    "import math\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "import copy\n",
    "from sklearn.calibration import CalibratedClassifierCV, calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from torchsummary import summary\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    average_precision_score,\n",
    "    roc_curve\n",
    ")\n",
    "\n",
    "config = load_config(path='../configs/config_finetune_resnet50.yaml')\n",
    "\n",
    "FIG_OUT  = os.path.join('..','outputs','figures', 'Switzerland', 'finetune_resnet50')\n",
    "\n",
    "# Génération du Run ID: date + git hash\n",
    "today = date.today().isoformat()\n",
    "commit = subprocess.check_output([\"git\",\"rev-parse\",\"--short\",\"HEAD\"]).decode().strip()\n",
    "run_id = f\"{today}_{commit}\"\n",
    "\n",
    "print(\"Run ID :\", run_id)"
   ],
   "id": "ed5be45a875ec18b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Data Preparation",
   "id": "1b23fa79931c4313"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define transforms based on config\n",
    "data_cfg = config['augmentation']\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(tuple(data_cfg['resize'])),\n",
    "    transforms.RandomHorizontalFlip() if data_cfg['horizontal_flip'] else transforms.Lambda(lambda x: x),\n",
    "    transforms.RandomRotation(data_cfg['rotation']),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_cfg['normalization']['mean'], std=data_cfg['normalization']['std'])\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = datasets.ImageFolder(root=os.path.join( '../', config['data']['path']), transform=train_transform)\n",
    "\n",
    "# Split into train/val\n",
    "total = len(dataset)\n",
    "train_size = int(config['data']['train_split'] * total)\n",
    "val_size = total - train_size\n",
    "train_set, val_set = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_set, batch_size=config['data']['batch_size'], shuffle=True, num_workers=config['data']['num_workers'])\n",
    "val_loader   = DataLoader(val_set,   batch_size=config['data']['batch_size'], shuffle=False, num_workers=config['data']['num_workers'])"
   ],
   "id": "b71b0e5988a8b6a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Model Definition",
   "id": "52e9d3cb870392c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_cfg = config['model']\n",
    "model = getattr(models, model_cfg['name'])(weights=ResNet50_Weights.DEFAULT)\n",
    "if hasattr(model, 'fc'):\n",
    "    in_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features, model_cfg['num_classes'])\n",
    "elif hasattr(model, 'classifier'):\n",
    "    in_features = model.classifier[-1].in_features\n",
    "    model.classifier[-1] = nn.Linear(in_features, model_cfg['num_classes'])\n",
    "model = model.to(config['training']['device'])"
   ],
   "id": "a3f799c36354e5a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. Training Loop",
   "id": "7df8d974fa5b6108"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=float(config['training']['learning_rate']), weight_decay=float(config['training']['weight_decay']))\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in tqdm(loader, desc='Train'):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += torch.sum(preds == labels.data)\n",
    "        total += labels.size(0)\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct.double() / total\n",
    "    return epoch_loss, epoch_acc.item()\n",
    "\n",
    "\n",
    "def eval_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_labels = []\n",
    "    all_preds  = []\n",
    "    all_probs  = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc='Val'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            probs  = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "            total += labels.size(0)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc  = correct.double() / total\n",
    "    return (\n",
    "        epoch_loss,\n",
    "        epoch_acc.item(),\n",
    "        np.array(all_labels),\n",
    "        np.array(all_preds),\n",
    "        np.array(all_probs)\n",
    "    )\n",
    "\n",
    "summary(model, input_size=(3, 64, 64))"
   ],
   "id": "785d585ae2ff463f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Training and validation\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_acc': [], 'val_acc': [],\n",
    "    'val_roc_auc': [],  'val_avg_prec': []\n",
    "}\n",
    "for epoch in range(config['training']['epochs']):\n",
    "    print(f\"Epoch {epoch+1}/{config['training']['epochs']}\")\n",
    "    t_loss, t_acc = train_one_epoch(model, train_loader, criterion, optimizer, config['training']['device'])\n",
    "    v_loss, v_acc, y_true, y_pred, y_prob = eval_model(model, val_loader, criterion, config['training']['device'])\n",
    "    history['train_loss'].append(t_loss)\n",
    "    history['val_loss'].append(v_loss)\n",
    "    history['train_acc'].append(t_acc)\n",
    "    history['val_acc'].append(v_acc)\n",
    "    roc_auc   = roc_auc_score(y_true, y_prob)\n",
    "    avg_prec  = average_precision_score(y_true, y_prob)\n",
    "    history['val_roc_auc'].append(roc_auc)\n",
    "    history['val_avg_prec'].append(avg_prec)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    patience = 5\n",
    "    num_bad_epochs = 0\n",
    "\n",
    "    if v_loss < best_val_loss:\n",
    "        best_val_loss = v_loss\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        num_bad_epochs = 0\n",
    "    else:\n",
    "        num_bad_epochs += 1\n",
    "\n",
    "    if num_bad_epochs >= patience:\n",
    "        print(f\"No improvement for {patience} epochs. Early stopping.\")\n",
    "        break\n",
    "\n",
    "    print(f\"Train loss: {t_loss:.4f}, acc: {t_acc:.4f} | Val loss: {v_loss:.4f}, acc: {v_acc:.4f} | ROC AUC: {roc_auc:.3f}, AP: {avg_prec:.3f}\")\n",
    "\n",
    "model.load_state_dict(best_model_wts)"
   ],
   "id": "1b4e97efe14ad412",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.makedirs('../outputs/logs/Switzerland/finetune_resnet50', exist_ok=True)\n",
    "hist_path = f\"../outputs/logs/Switzerland/finetune_resnet50/history_finetune_resnet50_{run_id}.pkl\"\n",
    "pd.to_pickle(history, hist_path)\n",
    "\n",
    "os.makedirs('../outputs/checkpoints/Switzerland/finetune_resnet50', exist_ok=True)\n",
    "hist_path = f\"../outputs/checkpoints/Switzerland/finetune_resnet50/history_finetune_resnet50_{run_id}.pkl\"\n",
    "pd.to_pickle(history, hist_path)"
   ],
   "id": "dc68a26c1da34e17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Results Visualization",
   "id": "519d876639dd3b2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot loss and accuracy curves\n",
    "epochs = range(1, config['training']['epochs']+1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, history['train_acc'], label='Train Acc')\n",
    "plt.plot(epochs, history['val_acc'], label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Sauvegarde de la figure des coubres accuracy\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_accuracy_curves.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Courbes sauvegardées dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "f5737f7951092ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "plt.plot(epochs, history['train_loss'], label='Train Loss')\n",
    "plt.plot(epochs, history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Sauvegarde de la figure des coubres loss\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_loss_curves.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Courbes sauvegardées dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "67a7fb13c2f3b5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "precision, recall, _ = precision_recall_curve(y_true, y_prob)\n",
    "roc_auc_val = roc_auc_score(y_true, y_prob)\n",
    "ap_val = average_precision_score(y_true, y_prob)\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC (AUC = {roc_auc_val:.2f})')\n",
    "plt.plot([0, 1], [0, 1], '--', alpha=0.5)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Sauvegarde de la figure d'ROC\n",
    "plt.savefig(os.path.join(FIG_OUT, f\"{run_id}_roc_curve.png\"), dpi=300)\n",
    "print(\"ROC sauvegardées dans :\", os.path.join(FIG_OUT, f\"{run_id}_roc_curve.png\"))\n",
    "plt.show()"
   ],
   "id": "2cc419ccbb671dc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot PR\n",
    "plt.figure()\n",
    "plt.plot(recall, precision, label=f'PR (AP = {ap_val:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(os.path.join(FIG_OUT, f\"{run_id}_pr_curve.png\"), dpi=300)\n",
    "print(\"ROC sauvegardées dans :\", os.path.join(FIG_OUT, f\"{run_id}_pr_curve.png\"))\n",
    "\n",
    "plt.show()"
   ],
   "id": "b123426fefb1ce08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Confusion matrix\n",
    "target_names = dataset.classes\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=target_names, yticklabels=target_names)\n",
    "plt.ylabel('True')\n",
    "plt.xlabel('Predicted')\n",
    "\n",
    "# Sauvegarde de la figure de confusion matrix\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_confusion_matrix.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Matrice sauvegardée dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "b1e860299a1f5c36",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Classification report\n",
    "# print(classification_report(y_true, y_pred, target_names=target_names))\n",
    "\n",
    "report_df = pd.DataFrame(classification_report(y_true, y_pred, target_names=target_names, output_dict=True)).T\n",
    "\n",
    "csv_path = os.path.join(FIG_OUT, f\"{run_id}_classification_report.csv\")\n",
    "report_df.to_csv(csv_path, index=True)\n",
    "print(\"Report CSV sauvegardé dans :\", csv_path)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, len(report_df) * 0.5 + 1))\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(\n",
    "    cellText=report_df.round(2).values,\n",
    "    rowLabels=report_df.index,\n",
    "    colLabels=report_df.columns,\n",
    "    loc='center'\n",
    ")\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(10)\n",
    "table.scale(1, 1.5)\n",
    "\n",
    "img_path = os.path.join(FIG_OUT, f\"{run_id}_classification_report.png\")\n",
    "fig.savefig(img_path, dpi=300, bbox_inches='tight')\n",
    "print(\"Report image sauvegardé dans :\", img_path)"
   ],
   "id": "a06690254098a793",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6. Calibration Platt (sigmoïde)",
   "id": "c4a290be60f5475d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "v_loss, v_acc, y_true_val, y_pred_val, y_prob_val = eval_model(\n",
    "    model, val_loader, criterion, config['training']['device']\n",
    ")\n",
    "\n",
    "class ModelWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    def predict_proba(self, X):\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = torch.stack([transforms.ToTensor()(img) for img in X]).to(config['training']['device'])\n",
    "            outputs = self.model(inputs)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()\n",
    "        return probs\n",
    "\n",
    "wrapper = ModelWrapper(model)\n",
    "calibrator = CalibratedClassifierCV(wrapper, cv='prefit', method='sigmoid')\n",
    "\n",
    "lr_cal = LogisticRegression().fit(\n",
    "    y_prob_val.reshape(-1,1),\n",
    "    y_true_val\n",
    ")\n",
    "\n",
    "y_prob_cal = lr_cal.predict_proba(y_prob_val.reshape(-1,1))[:,1]\n",
    "\n",
    "brier = brier_score_loss(y_true_val, y_prob_cal)\n",
    "print(f\"Brier score (calibré) : {brier:.4f}\")\n",
    "\n",
    "frac_pos, mean_pred = calibration_curve(y_true_val, y_prob_val, n_bins=10)\n",
    "frac_pos_cal, mean_pred_cal = calibration_curve(y_true_val, y_prob_cal, n_bins=10)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(mean_pred,   frac_pos,   's-', label='Non calibré')\n",
    "plt.plot(mean_pred_cal, frac_pos_cal, 's-', label='Calibré (Platt)')\n",
    "plt.plot([0,1], [0,1], 'k--', alpha=0.5)\n",
    "plt.xlabel('Probabilité prédite moyenne')\n",
    "plt.ylabel('Fraction positive réelle')\n",
    "plt.title('Calibration curve')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(FIG_OUT, f\"{run_id}_calibration_curve.png\"), dpi=300)\n",
    "plt.show()\n"
   ],
   "id": "a64a1529605f339c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 7. Grad-CAM Interpretability",
   "id": "ac4bbb53c1d1fe97"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "vis_transform = transforms.Compose([\n",
    "    transforms.Resize(tuple(data_cfg['resize'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=data_cfg['normalization']['mean'], std=data_cfg['normalization']['std'])\n",
    "])\n",
    "\n",
    "target_layer = model.layer4[-1].conv2\n",
    "cam_extractor = GradCAM(model=model, target_layers=[target_layer])\n",
    "\n",
    "n_display = 10\n",
    "\n",
    "n_cols = 5\n",
    "n_rows = math.ceil(n_display / n_cols)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols,\n",
    "                         figsize=(n_cols * 4, n_rows * 4),\n",
    "                         dpi=100)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx in range(n_display):\n",
    "    ax = axes[idx]\n",
    "\n",
    "    tensor_aug, true_label = val_set[idx+12]\n",
    "    orig_path, _ = val_set.dataset.samples[val_set.indices[idx+12]]\n",
    "    orig_img: Image.Image = Image.open(orig_path).convert('RGB')\n",
    "    W, H = orig_img.size\n",
    "\n",
    "    orig_resized = transforms.Resize(tuple(data_cfg['resize']))(orig_img)\n",
    "    input_tensor = vis_transform(orig_resized).unsqueeze(0)\n",
    "\n",
    "    outputs = model(input_tensor)\n",
    "    pred_label = outputs.argmax(dim=1).item()\n",
    "\n",
    "    grayscale_cam = cam_extractor(input_tensor=input_tensor)[0]\n",
    "\n",
    "    cam_img = Image.fromarray((grayscale_cam * 255).astype(np.uint8))\n",
    "    cam_img = cam_img.resize((W, H), resample=Image.BILINEAR)\n",
    "    cam_resized = np.array(cam_img, dtype=np.float32) / 255.0\n",
    "\n",
    "    rgb_orig = np.array(orig_img, dtype=np.float32) / 255.0\n",
    "    cam_on_orig = show_cam_on_image(rgb_orig, cam_resized, use_rgb=True)\n",
    "\n",
    "    ax.imshow(cam_on_orig)\n",
    "    ax.set_title(f\"True: {dataset.classes[true_label]}\\nPred: {dataset.classes[pred_label]}\",\n",
    "                 fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "for ax in axes[n_display:]:\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_path = os.path.join(FIG_OUT, f\"{run_id}_grad-cam.png\")\n",
    "plt.savefig(fig_path, dpi=300)\n",
    "print(\"Image sauvegardée dans :\", fig_path)\n",
    "\n",
    "plt.show()"
   ],
   "id": "8d2ba4380c01c94a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 8. Save Model & Config",
   "id": "d82a57f7ceae95be"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "os.makedirs('../outputs/checkpoints/Switzerland/finetune_resnet50', exist_ok=True)\n",
    "torch.save(model.state_dict(), f'../outputs/checkpoints/Switzerland/finetune_resnet50/{run_id}_model.pth')\n",
    "\n",
    "with open(f'../outputs/configs/Switzerland/{run_id}_config_finetune_resnet50.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print('Training complete. Model and config saved in outputs')"
   ],
   "id": "e1b91cc582573537",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
